# Plano de ReestruturaÃ§Ã£o: modules/ml/

> **Status**: Rascunho - ReorganizaÃ§Ã£o Completa de ML Modules
> **Criado**: 2025-11-26
> **Objetivo**: Modularizar, eliminar sobreposiÃ§Ã£o, melhorar manutenibilidade

---

## Resumo Executivo

A pasta `modules/ml/` contÃ©m infraestrutura ML crÃ­tica, mas sofre de:
- **SobreposiÃ§Ã£o funcional** entre componentes
- **Falta de hierarquia clara** (serviÃ§os vs infraestrutura vs aplicaÃ§Ãµes)
- **MÃºltiplos pontos de entrada** sem agregaÃ§Ã£o clara
- **Projetos grandes misturados** com mÃ³dulos pequenos

Este plano propÃµe reorganizar em estrutura modular clara, separando:
- **ServiÃ§os ML** (llama.cpp, Ollama)
- **Infraestrutura** (storage, VRAM, offload)
- **AplicaÃ§Ãµes** (unified-llm/SecureLLM Bridge)
- **IntegraÃ§Ãµes** (MCP servers, APIs)

---

## AnÃ¡lise da Estrutura Atual

### Estado Atual
```
modules/ml/
â”œâ”€â”€ llama.nix                    # ServiÃ§o llama.cpp (207 linhas)
â”œâ”€â”€ models-storage.nix           # Storage padronizado (130 linhas)
â”œâ”€â”€ ollama-gpu-manager.nix       # Gerenciamento GPU Ollama (133 linhas)
â”œâ”€â”€ mcp-config/                  # ConfiguraÃ§Ã£o MCP
â”‚   â””â”€â”€ default.nix
â”œâ”€â”€ offload/                     # Sistema unificado de offload
â”‚   â”œâ”€â”€ default.nix             # Agregador principal
â”‚   â”œâ”€â”€ manager.nix             # Gerenciador de offload
â”‚   â”œâ”€â”€ model-registry.nix      # Registro de modelos
â”‚   â”œâ”€â”€ vram-intelligence.nix   # InteligÃªncia VRAM
â”‚   â”œâ”€â”€ backends/               # Backends (Ollama, llama.cpp, vLLM, TGI)
â”‚   â”‚   â””â”€â”€ default.nix
â”‚   â”œâ”€â”€ api/                    # API REST Rust
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ target/
â”‚   â”œâ”€â”€ neovim/                 # IntegraÃ§Ã£o Neovim
â”‚   â””â”€â”€ flake.nix
â””â”€â”€ unified-llm/                 # SecureLLM Bridge (projeto grande)
    â”œâ”€â”€ Cargo.toml
    â”œâ”€â”€ CLAUDE.md               # 807 linhas de docs
    â”œâ”€â”€ crates/
    â”‚   â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ security/
    â”‚   â”œâ”€â”€ providers/
    â”‚   â”œâ”€â”€ cli/
    â”‚   â””â”€â”€ api-server/
    â”œâ”€â”€ mcp-server/             # MCP Server TypeScript
    â”‚   â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ package.json
    â”‚   â””â”€â”€ knowledge.db
    â”œâ”€â”€ docs/
    â”œâ”€â”€ examples/
    â”œâ”€â”€ docker/
    â””â”€â”€ flake.nix
```

### MÃ©tricas
- **Total de arquivos .nix no ml/**: 6 arquivos raiz + mÃºltiplos subdiretÃ³rios
- **Maior projeto**: unified-llm/ (~1.5MB, projeto Rust completo)
- **API Rust duplicada**: offload/api/ vs unified-llm/crates/api-server/
- **MCP servers**: 2 instÃ¢ncias (mcp-config/ + unified-llm/mcp-server/)
- **Build artifacts**: target/ com 1.8MB em offload/api/

---

## Problemas Identificados

### ğŸ”´ CrÃ­ticos

#### 1. SobreposiÃ§Ã£o Funcional: API Servers
**Problema**: Duas APIs Rust diferentes:
- `offload/api/` - API REST para offload (Python + Rust)
- `unified-llm/crates/api-server/` - API REST para SecureLLM Bridge

**AnÃ¡lise**:
- Ambas servem endpoints HTTP
- Ambas gerenciam providers LLM
- `offload/api/` foca em VRAM e model registry
- `unified-llm` foca em seguranÃ§a e proxy LLM

**DecisÃ£o necessÃ¡ria**:
- **OpÃ§Ã£o A**: Manter separadas (propÃ³sitos diferentes)
- **OpÃ§Ã£o B**: Unificar em API single (mais complexo)
- **OpÃ§Ã£o C**: unified-llm consome offload/api como backend

#### 2. SobreposiÃ§Ã£o Funcional: GPU Management
**Problema**: Gerenciamento de GPU em mÃºltiplos lugares:
- `ollama-gpu-manager.nix` - Auto-offload para Ollama
- `offload/vram-intelligence.nix` - VRAM monitoring geral
- `unified-llm` - Provider-aware resource management

**Conflito**: MÃºltiplos sistemas tentando gerenciar mesma GPU

#### 3. MCP Servers Duplicados
**Problema**:
- `mcp-config/default.nix` - Config MCP genÃ©rica
- `unified-llm/mcp-server/` - MCP server completo (TypeScript)

**AnÃ¡lise**:
- `mcp-config/` parece stub ou config
- `unified-llm/mcp-server/` Ã© implementaÃ§Ã£o completa
- Unclear qual Ã© usado

#### 4. Projeto Grande Dentro de modules/
**Problema**: `unified-llm/` Ã© projeto standalone completo:
- Workspace Cargo multi-crate
- Sistema de build prÃ³prio (flake.nix)
- DocumentaÃ§Ã£o extensa (CLAUDE.md)
- Docker, examples, testes

**QuestÃ£o**: Deveria estar em `/etc/nixos/modules/` ou em local separado?

### âš ï¸ Alta Prioridade

#### 5. Falta de default.nix Principal
**Problema**: Nenhum `modules/ml/default.nix` agregando tudo
**Impacto**: Imports verbosos no flake.nix

#### 6. Build Artifacts no Repo
**Problema**:
- `offload/api/target/` (artifacts Rust)
- `unified-llm/target/` (artifacts Rust)
- `unified-llm/mcp-server/knowledge.db*` (database runtime)

**Risco**: Repo inchado, conflicts git

#### 7. Storage Management Fragmentado
**Problema**:
- `models-storage.nix` - Storage paths
- `offload/model-registry.nix` - Model registry DB
- Cada serviÃ§o tem seu path

**Resultado**: Confusion sobre onde modelos ficam

### ğŸ’¡ Oportunidades

#### 8. ModularizaÃ§Ã£o Clara
**Oportunidade**: Separar em camadas:
- **Infraestrutura**: Storage, VRAM, hardware
- **ServiÃ§os**: llama.cpp, Ollama services
- **OrquestraÃ§Ã£o**: Offload manager, registry
- **AplicaÃ§Ãµes**: SecureLLM Bridge
- **IntegraÃ§Ãµes**: MCP servers, APIs

#### 9. Default.nix por Categoria
**Oportunidade**: Criar aggregators:
```nix
modules/ml/services/default.nix       # Agrega todos serviÃ§os ML
modules/ml/infrastructure/default.nix # Agrega storage, VRAM
modules/ml/applications/default.nix   # Agrega apps (unified-llm)
```

---

## Estrutura Proposta

### OpÃ§Ã£o A: Hierarquia por FunÃ§Ã£o (Recomendado)

```
modules/ml/
â”œâ”€â”€ default.nix                      # Agregador principal (NOVO)
â”‚
â”œâ”€â”€ infrastructure/                  # Infraestrutura base (NOVO)
â”‚   â”œâ”€â”€ default.nix                 # Agrega infra
â”‚   â”œâ”€â”€ storage.nix                 # models-storage.nix renomeado
â”‚   â”œâ”€â”€ vram/                       # VRAM management (NOVO)
â”‚   â”‚   â”œâ”€â”€ default.nix
â”‚   â”‚   â”œâ”€â”€ monitoring.nix          # De offload/vram-intelligence.nix
â”‚   â”‚   â””â”€â”€ scheduler.nix           # GPU scheduling logic
â”‚   â””â”€â”€ hardware/                   # Hardware config (NOVO)
â”‚       â””â”€â”€ cuda.nix                # CUDA/GPU specific
â”‚
â”œâ”€â”€ services/                        # ServiÃ§os ML (NOVO)
â”‚   â”œâ”€â”€ default.nix                 # Agrega serviÃ§os
â”‚   â”œâ”€â”€ llama-cpp.nix               # llama.nix renomeado
â”‚   â”œâ”€â”€ ollama/                     # Ollama service + management (NOVO)
â”‚   â”‚   â”œâ”€â”€ default.nix
â”‚   â”‚   â”œâ”€â”€ service.nix             # Base Ollama service
â”‚   â”‚   â””â”€â”€ gpu-manager.nix         # ollama-gpu-manager.nix movido
â”‚   â””â”€â”€ vllm.nix                    # vLLM service (FUTURO)
â”‚
â”œâ”€â”€ orchestration/                   # OrquestraÃ§Ã£o & offload (NOVO)
â”‚   â”œâ”€â”€ default.nix                 # De offload/default.nix
â”‚   â”œâ”€â”€ manager.nix                 # De offload/manager.nix
â”‚   â”œâ”€â”€ registry/                   # Model registry (NOVO)
â”‚   â”‚   â”œâ”€â”€ default.nix
â”‚   â”‚   â”œâ”€â”€ database.nix            # SQLite registry
â”‚   â”‚   â””â”€â”€ discovery.nix           # Auto-discovery
â”‚   â”œâ”€â”€ backends/                   # De offload/backends/
â”‚   â”‚   â”œâ”€â”€ default.nix
â”‚   â”‚   â”œâ”€â”€ ollama.nix
â”‚   â”‚   â”œâ”€â”€ llamacpp.nix
â”‚   â”‚   â”œâ”€â”€ vllm.nix
â”‚   â”‚   â””â”€â”€ tgi.nix
â”‚   â””â”€â”€ api/                        # De offload/api/
â”‚       â”œâ”€â”€ flake.nix
â”‚       â”œâ”€â”€ Cargo.toml
â”‚       â””â”€â”€ src/
â”‚
â”œâ”€â”€ applications/                    # Apps standalone (NOVO)
â”‚   â”œâ”€â”€ default.nix                 # Agrega apps
â”‚   â””â”€â”€ securellm-bridge/           # unified-llm/ renomeado
â”‚       â”œâ”€â”€ flake.nix
â”‚       â”œâ”€â”€ CLAUDE.md
â”‚       â”œâ”€â”€ crates/
â”‚       â”œâ”€â”€ mcp-server/
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ integrations/                    # IntegraÃ§Ãµes externas (NOVO)
    â”œâ”€â”€ default.nix
    â”œâ”€â”€ mcp/                        # MCP integration
    â”‚   â”œâ”€â”€ default.nix             # De mcp-config/
    â”‚   â””â”€â”€ config.nix
    â””â”€â”€ neovim/                     # De offload/neovim/
        â””â”€â”€ README.md
```

### OpÃ§Ã£o B: Hierarquia Flat com Prefixos

```
modules/ml/
â”œâ”€â”€ default.nix
â”œâ”€â”€ core-storage.nix                # models-storage.nix
â”œâ”€â”€ core-vram-monitoring.nix        # offload/vram-intelligence.nix
â”œâ”€â”€ core-vram-scheduler.nix         # GPU scheduling
â”œâ”€â”€ service-llamacpp.nix            # llama.nix
â”œâ”€â”€ service-ollama.nix              # Ollama service
â”œâ”€â”€ service-ollama-gpu.nix          # ollama-gpu-manager.nix
â”œâ”€â”€ orchestration-manager.nix       # offload/manager.nix
â”œâ”€â”€ orchestration-registry.nix      # offload/model-registry.nix
â”œâ”€â”€ orchestration-backends.nix      # offload/backends/
â”œâ”€â”€ app-securellm-bridge/           # unified-llm/
â””â”€â”€ integration-mcp/                # mcp-config/
```

**AnÃ¡lise de OpÃ§Ãµes**:
- **OpÃ§Ã£o A**: Mais clara hierarquia, melhor escalabilidade
- **OpÃ§Ã£o B**: Mais flat, mais fÃ¡cil encontrar arquivos especÃ­ficos
- **RecomendaÃ§Ã£o**: **OpÃ§Ã£o A** para melhor organizaÃ§Ã£o a longo prazo

---

## DecisÃµes Arquiteturais

### DecisÃ£o 1: unified-llm/ Location

**Pergunta**: unified-llm/ deve ficar em `modules/ml/` ou mover para `/etc/nixos/apps/`?

**OpÃ§Ãµes**:
1. **Manter em modules/ml/applications/** - Ã‰ infraestrutura ML
2. **Mover para /etc/nixos/apps/** - Ã‰ aplicaÃ§Ã£o standalone
3. **Mover para /etc/nixos/services/** - Ã‰ serviÃ§o system-wide

**RecomendaÃ§Ã£o**: **OpÃ§Ã£o 1** - Manter em `modules/ml/applications/securellm-bridge/`
- Faz parte da stack ML
- Integra com offload/
- NÃ£o Ã© app user-space (Ã© infraestrutura)

### DecisÃ£o 2: APIs Rust - Merge ou Separar?

**Pergunta**: Unificar `offload/api/` e `unified-llm/crates/api-server/`?

**AnÃ¡lise**:
- `offload/api/` - VRAM monitoring, model registry, backend management
- `unified-llm/api-server/` - Secure LLM proxy, rate limiting, audit

**PropÃ³sitos diferentes**:
- offload/api â†’ **Internal management API** (VRAM, models, backends)
- unified-llm â†’ **External proxy API** (secure LLM access)

**RecomendaÃ§Ã£o**: **Manter separadas**
- unified-llm pode **consumir** offload/api como backend
- offload/api = infraestrutura interna
- unified-llm = gateway externo

**IntegraÃ§Ã£o**:
```rust
// unified-llm/crates/providers/src/local.rs
pub struct LocalProvider {
    offload_api_client: OffloadApiClient, // http://localhost:9000
}

impl LocalProvider {
    async fn check_vram(&self) -> Result<VramState> {
        self.offload_api_client.get("/vram/status").await
    }
}
```

### DecisÃ£o 3: GPU Management - Centralizar ou Distribuir?

**Pergunta**: Centralizar VRAM management ou deixar por serviÃ§o?

**AnÃ¡lise atual**:
- `ollama-gpu-manager.nix` - Ollama-specific idle detection
- `offload/vram-intelligence.nix` - Generic VRAM monitoring
- Potential conflicts se ambos tentam gerenciar GPU

**RecomendaÃ§Ã£o**: **Arquitetura em camadas**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  infrastructure/vram/scheduler.nix        â”‚  â† Central scheduler
â”‚  (Single source of truth para GPU)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ Ollama â”‚  â”‚llama.cpp â”‚  â”‚  vLLM   â”‚  â† Services request GPU
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ImplementaÃ§Ã£o**:
- `infrastructure/vram/scheduler.nix` - Central VRAM scheduler
- Services registram com scheduler
- Scheduler aloca VRAM baseado em prioridade
- `ollama-gpu-manager` se torna client do scheduler

### DecisÃ£o 4: MCP Servers

**Pergunta**: Quantos MCP servers manter?

**AnÃ¡lise**:
- `mcp-config/default.nix` - Parece config stub
- `unified-llm/mcp-server/` - Full TypeScript implementation

**RecomendaÃ§Ã£o**: **Single MCP server em integrations/**

```
modules/ml/integrations/mcp/
â”œâ”€â”€ default.nix              # Config Nix
â”œâ”€â”€ server/                  # unified-llm/mcp-server/ movido
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ knowledge.db
â””â”€â”€ config.nix               # mcp-config merged
```

---

## Plano de MigraÃ§Ã£o

### Fase 1: PreparaÃ§Ã£o (Dia 1)

#### 1.1 Backup & Git Tag
```bash
# Tag estado atual
git tag -a ml-restructure-pre -m "Before ML modules restructure"
git push origin ml-restructure-pre

# Backup completo
sudo cp -a /etc/nixos/modules/ml /etc/nixos/modules/ml.backup-$(date +%Y%m%d)
```

#### 1.2 Criar Nova Estrutura (DiretÃ³rios Vazios)
```bash
cd /etc/nixos/modules/ml

# Criar nova hierarquia
mkdir -p infrastructure/{vram,hardware}
mkdir -p services/ollama
mkdir -p orchestration/{registry,backends,api}
mkdir -p applications
mkdir -p integrations/{mcp/server,neovim}
```

#### 1.3 Criar Aggregators (default.nix)
```bash
# Criar todos os default.nix necessÃ¡rios
touch default.nix
touch infrastructure/default.nix
touch services/default.nix
touch orchestration/default.nix
touch applications/default.nix
touch integrations/default.nix
```

### Fase 2: MigraÃ§Ã£o de Arquivos (Dia 2-3)

#### 2.1 Infrastructure Layer
```bash
# Storage
git mv modules/ml/models-storage.nix modules/ml/infrastructure/storage.nix

# VRAM
git mv modules/ml/offload/vram-intelligence.nix modules/ml/infrastructure/vram/monitoring.nix

# Criar scheduler novo (nÃ£o existe ainda)
# TODO: Extrair scheduling logic do offload/manager.nix
```

#### 2.2 Services Layer
```bash
# LLaMA C++
git mv modules/ml/llama.nix modules/ml/services/llama-cpp.nix

# Ollama
git mv modules/ml/ollama-gpu-manager.nix modules/ml/services/ollama/gpu-manager.nix

# Criar Ollama service base
# TODO: Extrair do configuration.nix se existir
```

#### 2.3 Orchestration Layer
```bash
# Manager & Registry
git mv modules/ml/offload/manager.nix modules/ml/orchestration/manager.nix
git mv modules/ml/offload/model-registry.nix modules/ml/orchestration/registry/database.nix

# Backends
git mv modules/ml/offload/backends modules/ml/orchestration/backends

# API (manter estrutura)
git mv modules/ml/offload/api modules/ml/orchestration/api

# Cleanup offload flake
# Decidir: manter flake ou integrar no flake principal
```

#### 2.4 Applications Layer
```bash
# Unified LLM â†’ SecureLLM Bridge
git mv modules/ml/unified-llm modules/ml/applications/securellm-bridge
```

#### 2.5 Integrations Layer
```bash
# MCP
git mv modules/ml/unified-llm/mcp-server modules/ml/integrations/mcp/server
git mv modules/ml/mcp-config modules/ml/integrations/mcp/config

# Neovim
git mv modules/ml/offload/neovim modules/ml/integrations/neovim
```

### Fase 3: Atualizar Imports (Dia 3-4)

#### 3.1 Criar default.nix Principal
```nix
# modules/ml/default.nix
{
  imports = [
    ./infrastructure
    ./services
    ./orchestration
    ./applications
    ./integrations
  ];
}
```

#### 3.2 Criar Aggregators por Layer
```nix
# modules/ml/infrastructure/default.nix
{
  imports = [
    ./storage.nix
    ./vram
    ./hardware
  ];
}

# modules/ml/services/default.nix
{
  imports = [
    ./llama-cpp.nix
    ./ollama
  ];
}

# modules/ml/orchestration/default.nix
{
  imports = [
    ./manager.nix
    ./registry
    ./backends
  ];
}

# modules/ml/applications/default.nix
{
  imports = [
    ./securellm-bridge
  ];
}

# modules/ml/integrations/default.nix
{
  imports = [
    ./mcp
    ./neovim
  ];
}
```

#### 3.3 Atualizar flake.nix
```nix
# /etc/nixos/flake.nix

# DE:
./modules/ml/llama.nix
./modules/ml/models-storage.nix
./modules/ml/ollama-gpu-manager.nix
./modules/ml/offload
./modules/ml/unified-llm

# PARA:
./modules/ml  # Single import!
```

#### 3.4 Atualizar ReferÃªncias Internas
```bash
# Procurar todos imports que referenciam paths antigos
grep -r "modules/ml/llama.nix" /etc/nixos --include="*.nix"
grep -r "modules/ml/offload" /etc/nixos --include="*.nix"
grep -r "modules/ml/unified-llm" /etc/nixos --include="*.nix"

# Atualizar cada referÃªncia encontrada
```

### Fase 4: ValidaÃ§Ã£o & Testes (Dia 4-5)

#### 4.1 Validar Sintaxe
```bash
# Check flake
nix flake check

# Se falhar, usar --show-trace
nix flake check --show-trace
```

#### 4.2 Build Test
```bash
# Build sem aplicar
sudo nixos-rebuild build --flake /etc/nixos#kernelcore

# Verificar que gerou derivation
ls -la /nix/store/*-nixos-system-*/
```

#### 4.3 Verificar Imports
```bash
# Listar todas imports que serÃ£o incluÃ­das
nix-instantiate --eval --strict -E '
  with import <nixpkgs> {};
  (import /etc/nixos/flake.nix).nixosConfigurations.kernelcore.imports
'
```

#### 4.4 Dry-Run Activation
```bash
# Dry activation para ver mudanÃ§as
sudo nixos-rebuild dry-activate --flake /etc/nixos#kernelcore
```

### Fase 5: Deploy (Dia 5)

#### 5.1 Rebuild & Switch
```bash
# Rebuild final
sudo nixos-rebuild switch --flake /etc/nixos#kernelcore

# Watch journal para erros
sudo journalctl -xef
```

#### 5.2 Verificar ServiÃ§os
```bash
# Check ML services
systemctl status llamacpp
systemctl status ollama
systemctl status ml-offload-api
systemctl status ollama-gpu-idle-monitor

# Check VRAM
nvidia-smi
```

#### 5.3 Testar Funcionalidade
```bash
# Test llama.cpp
curl http://127.0.0.1:8080/health

# Test Ollama
ollama list

# Test offload API
curl http://localhost:9000/health

# Test unified-llm (se enabled)
# ...
```

### Fase 6: Cleanup (Dia 6)

#### 6.1 Remover DiretÃ³rios Antigos
```bash
# Remover offload/ vazio (se tudo foi movido)
rmdir /etc/nixos/modules/ml/offload

# Remover mcp-config/ vazio
rmdir /etc/nixos/modules/ml/mcp-config

# Verificar que nada foi esquecido
find /etc/nixos/modules/ml -maxdepth 1 -type f -name "*.nix"
```

#### 6.2 Limpar Build Artifacts
```bash
# Adicionar ao .gitignore
echo "modules/ml/**/target/" >> /etc/nixos/.gitignore
echo "modules/ml/**/*.db" >> /etc/nixos/.gitignore
echo "modules/ml/**/*.db-shm" >> /etc/nixos/.gitignore
echo "modules/ml/**/*.db-wal" >> /etc/nixos/.gitignore

# Remover artifacts existentes
rm -rf modules/ml/orchestration/api/target
rm -rf modules/ml/applications/securellm-bridge/target
rm -rf modules/ml/integrations/mcp/server/*.db*
```

#### 6.3 Commit MigraÃ§Ã£o
```bash
cd /etc/nixos

git add modules/ml/
git commit -m "refactor(ml): Complete ML modules restructure

## Changes:

### New Hierarchical Structure
Created clear separation by function:
- infrastructure/ - Storage, VRAM, hardware
- services/ - llama.cpp, Ollama services
- orchestration/ - Offload manager, registry, backends, API
- applications/ - SecureLLM Bridge (unified-llm renamed)
- integrations/ - MCP server, Neovim

### File Migrations
- llama.nix â†’ services/llama-cpp.nix
- models-storage.nix â†’ infrastructure/storage.nix
- ollama-gpu-manager.nix â†’ services/ollama/gpu-manager.nix
- offload/vram-intelligence.nix â†’ infrastructure/vram/monitoring.nix
- offload/manager.nix â†’ orchestration/manager.nix
- offload/model-registry.nix â†’ orchestration/registry/database.nix
- offload/backends â†’ orchestration/backends
- offload/api â†’ orchestration/api
- unified-llm â†’ applications/securellm-bridge
- unified-llm/mcp-server â†’ integrations/mcp/server
- mcp-config â†’ integrations/mcp/config

### Benefits
âœ… Clear module hierarchy by function
âœ… Single import point (modules/ml)
âœ… Eliminated overlapping functionality
âœ… Better scalability for future additions
âœ… Reduced flake.nix import verbosity (~5 imports â†’ 1 import)

### Testing
- [x] nix flake check passed
- [x] nixos-rebuild build successful
- [x] All ML services started correctly
- [x] VRAM monitoring operational
- [x] No functional regressions

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
```

#### 6.4 Tag ConclusÃ£o
```bash
git tag -a ml-restructure-complete -m "ML modules restructure completed"
git push origin ml-restructure-complete
```

### Fase 7: DocumentaÃ§Ã£o (Dia 7)

#### 7.1 Atualizar README
```bash
# Criar README principal
cat > modules/ml/README.md << 'EOF'
# ML Modules - Machine Learning Infrastructure

Modular ML infrastructure for NixOS with VRAM management, model orchestration, and secure LLM access.

## Structure

- **infrastructure/** - Storage, VRAM monitoring, hardware configs
- **services/** - ML services (llama.cpp, Ollama)
- **orchestration/** - Offload manager, model registry, backends
- **applications/** - Standalone ML apps (SecureLLM Bridge)
- **integrations/** - External integrations (MCP, Neovim)

## Quick Start

```nix
# Enable ML infrastructure
kernelcore.ml = {
  # Infrastructure
  models-storage.enable = true;

  # Services
  services.llamacpp.enable = true;
  services.ollama.enable = true;

  # Orchestration
  offload.enable = true;
};
```

See individual module READMEs for detailed configuration.
EOF
```

#### 7.2 Criar READMEs por Layer
```bash
# Infrastructure
touch modules/ml/infrastructure/README.md

# Services
touch modules/ml/services/README.md

# Orchestration
touch modules/ml/orchestration/README.md

# Applications
touch modules/ml/applications/README.md

# Integrations
touch modules/ml/integrations/README.md
```

#### 7.3 Atualizar CLAUDE.md Principal
```bash
# Atualizar /etc/nixos/CLAUDE.md com nova estrutura
# Adicionar seÃ§Ã£o sobre ML modules organization
```

---

## Rollback Strategy

### Se Problemas Ocorrerem

#### OpÃ§Ã£o 1: Git Reset
```bash
# Rollback git changes
git reset --hard ml-restructure-pre
sudo nixos-rebuild switch --flake /etc/nixos#kernelcore
```

#### OpÃ§Ã£o 2: System Rollback
```bash
# Rollback para geraÃ§Ã£o anterior
sudo nixos-rebuild switch --rollback
```

#### OpÃ§Ã£o 3: Restore Backup
```bash
# Restaurar backup completo
sudo rm -rf /etc/nixos/modules/ml
sudo cp -a /etc/nixos/modules/ml.backup-YYYYMMDD /etc/nixos/modules/ml
sudo nixos-rebuild switch --flake /etc/nixos#kernelcore
```

---

## MÃ©tricas de Sucesso

### ApÃ³s MigraÃ§Ã£o Completa

**Estrutura**:
- âœ… Hierarquia clara por funÃ§Ã£o (5 layers)
- âœ… Todos mÃ³dulos com default.nix aggregator
- âœ… Zero sobreposiÃ§Ã£o funcional
- âœ… Build artifacts removidos do repo

**Imports**:
- âœ… flake.nix imports reduzidos (5+ â†’ 1)
- âœ… Todos imports relativos corretos
- âœ… Nenhum path absoluto hardcoded

**Funcionalidade**:
- âœ… Todos serviÃ§os ML funcionando
- âœ… VRAM monitoring operacional
- âœ… Model registry funcional
- âœ… SecureLLM Bridge operacional
- âœ… MCP server acessÃ­vel

**DocumentaÃ§Ã£o**:
- âœ… README.md em cada layer
- âœ… CLAUDE.md atualizado
- âœ… Migration guide disponÃ­vel

---

## PrÃ³ximos Passos

### ApÃ³s ReestruturaÃ§Ã£o

1. **Implementar Central VRAM Scheduler** (infrastructure/vram/scheduler.nix)
   - Substituir GPU management distribuÃ­do
   - Single source of truth para GPU allocation

2. **Integrar unified-llm com offload/api**
   - LocalProvider consume offload API
   - Intelligent model selection baseado em VRAM

3. **Consolidar MCP Servers**
   - Single MCP server em integrations/mcp/
   - Tools para todos componentes ML

4. **Criar Testes Integrados**
   - Test suite para ML stack completa
   - Integration tests entre layers

5. **Performance Optimization**
   - Model loading time
   - VRAM allocation efficiency
   - API response times

---

## QuestÃµes para ResoluÃ§Ã£o

Antes de executar migraÃ§Ã£o, decidir:

1. **unified-llm location**: Manter em modules/ml/applications/ ou mover?
   - **RecomendaÃ§Ã£o**: Manter (Ã© infraestrutura ML)

2. **APIs Rust**: Unificar offload/api e unified-llm/api-server?
   - **RecomendaÃ§Ã£o**: Manter separadas, unified-llm consome offload/api

3. **GPU Management**: Centralizar em scheduler Ãºnico?
   - **RecomendaÃ§Ã£o**: Sim, criar infrastructure/vram/scheduler.nix

4. **MCP Servers**: Quantos manter?
   - **RecomendaÃ§Ã£o**: 1 em integrations/mcp/server/

5. **Build Artifacts**: Adicionar ao .gitignore?
   - **RecomendaÃ§Ã£o**: Sim, target/ e *.db nÃ£o devem estar no repo

6. **Flake Separation**: Manter flake.nix em subprojetos?
   - **RecomendaÃ§Ã£o**: Sim para orchestration/api e applications/securellm-bridge

---

## Arquitetura Final Proposta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    modules/ml/                              â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  infrastructure/                                     â”‚   â”‚
â”‚  â”‚  - storage.nix (model paths, directories)            â”‚   â”‚
â”‚  â”‚  - vram/monitoring.nix (VRAM metrics)                â”‚   â”‚
â”‚  â”‚  - vram/scheduler.nix (GPU allocation) â† CENTRAL     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  services/                                           â”‚   â”‚
â”‚  â”‚  - llama-cpp.nix (llama.cpp systemd service)         â”‚   â”‚
â”‚  â”‚  - ollama/service.nix (Ollama systemd)               â”‚   â”‚
â”‚  â”‚  - ollama/gpu-manager.nix (client do scheduler)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  orchestration/                                      â”‚   â”‚
â”‚  â”‚  - manager.nix (offload orchestration)               â”‚   â”‚
â”‚  â”‚  - registry/ (model discovery & DB)                  â”‚   â”‚
â”‚  â”‚  - backends/ (Ollama, llama.cpp, vLLM, TGI)          â”‚   â”‚
â”‚  â”‚  - api/ (Rust REST API port 9000)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  applications/                                       â”‚   â”‚
â”‚  â”‚  - securellm-bridge/ (ex unified-llm)                â”‚   â”‚
â”‚  â”‚    - Secure LLM proxy                                â”‚   â”‚
â”‚  â”‚    - Consumes orchestration/api                      â”‚   â”‚
â”‚  â”‚    - Provides external API                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  integrations/                                       â”‚   â”‚
â”‚  â”‚  - mcp/server/ (MCP server TypeScript)               â”‚   â”‚
â”‚  â”‚  - mcp/config.nix (MCP configuration)                â”‚   â”‚
â”‚  â”‚  - neovim/ (Neovim integration)                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**VersÃ£o do Documento**: 1.0.0
**Ãšltima AtualizaÃ§Ã£o**: 2025-11-26
**Mantido Por**: kernelcore
**Cronograma de RevisÃ£o**: ApÃ³s cada fase de migraÃ§Ã£o
